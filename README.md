# SEO
Resumo das principais técnicas de SEO, para que o site tenha destaque nas buscas.

## Spiders
Googlebot é o robô de rastreamento da Web do Google (também chamado de "indexador"). O rastreamento é o processo pelo qual o Googlebot descobre páginas novas e atualizadas para serem incluídas no índice do Google.

## Briefing de SEO
### Perguntas que você deve fazer sempre, antes de começar um projeto de SEO
* Qual serviço ou produto você vende em seu site?
* Como seus clientes procuram por seus produtos e serviços nos buscadores?
* Quais são os objetivos de negócio com o projeto de SEO?
* Faça o keyword research
* O que será que a pessoa digitaria nas buscas para nos encontrar?
* O que já está sendo devolvido nos resultados por essas buscas?
* Quais palavras-chaves devo utilizar?
* Devo priorizar palavras-chaves populares ou a cauda longa?
* Como saber se vale a pena rankear para determinada palavra-chave?
* Como calcular o ::Keyword Effectiveness Index ─ KEI:: (Índice de efetividade da palavra-chave) para saber se ela é uma palavra * interessante ou não?
* Quais palavras devo atacar no começo e quais guardar para o futuro?
* E várias outras que serão naturalmente respondidas durante o capítulo.
* Busque pelos termos que você quer rankear

## Começando a pesquisa das palavras-chave
Procure variações variações para as palavras que você quer usar. Uma boa ferramenta para fazer essa análise é o Google Trends ─ <http://trends.google.com>, que também nos diz o nível de interesse (buscas) por determinados termos de acordo com o tempo. Para conhecer e explorar as diferentes opções de palavras-chaves, podemos usar um serviço como o <http://keywordtool.io>.

## Instale o Google Analytics
O Analytics é capaz de identificar além da tradicional taxa de exibição e hit de uma página, localização geográfica do visitante, forma com a qual chegou na página (através de links de outros sites, buscador, AdSense ou diretamente pelo endereço), sistema operacional, navegador, navegador e sistema operacional combinados e suas versões, resolução de tela, Java, reprodutor de flash instalado, entre outros, em períodos diários, semanais, mensais e anuais.

## Configure o Webmaster Tools 

### 1. Data Highlighter
Esta ferramenta é uma forma de ajudar manualmente o Google a entender como é o seu site – onde em cada página está o título, a data, o nome do autor, a imagem, etc.

### 2. HTML Improvements
Ferramenta simples e muito útil: informa erros no HTML do seu site para que você os corrija rapidamente.

### 3. Search Queries
A melhor e mais popular ferramenta do Webmaster Tools responde à pergunta: “como as pessoas chegam ao meu site?”. Aqui você vai descobrir quais palavras-chave as pessoas estão digitando no Google, em quais páginas do seu site elas clicam, e como anda a audiência do seu site.

### 4. Links to Your Site
Esta é a melhor forma de medir a popularidade do seu site, bem como de medir um dos principais fatores no seu SEO: muitos links de sites variados e blogs de especialistas. Se a lista aqui é magra, pode ser hora de repensar o conteúdo e/ou de fazer guest blogging.

### 5. Internal Links
A outra metade da laranja. O Google “curte” sites bem amarrados, com abundância de links internos e sem páginas “órfãs”. Você pode detectá-las rapidamente aqui e também ver quais páginas do seu site poderiam receber um pouco mais de links internos.

### 6. PageSpeed Insights
Use o PageSpeed para conseguir automaticamente dicas personalizadas de como fazer um site mais rápido otimizando as imagens, por exemplo.

### 7. Search Appearance
Aqui, você consegue ter acesso a como seu site aparece nos resultados de busca.
Através da ‘Pesquisa de Aparência’, você terá acesso à quais são as influências do seu site nos buscadores, e isso, de fato, poderá te ajudar a verificar a taxa de cliques recebidos.

### 8. Google Index
Trata-se da seção onde você pode ver como as suas páginas têm sido indexadas no Google e também retirar as URL’s que você não deseja que apareçam.

### 9. Index Status
O Index Status demonstra a quantidade de páginas que estão indexadas. Aqui estão as URLs acessíveis pelo Googlebot – e também que estão bloqueadas pelo robots.txt ou precisam de um login para serem operadas.

### 10. Blocked Resources
Tratam-se das páginas que estão bloqueadas pelas regras de acesso arquivo robots.txt.

### 11. Crawl Errors
É recomendado verificar regularmente o relatório de erros de rastreamento.
Todos os erros que o Googlebot encontra ao rastrear seus sites são demonstrados aqui. Códigos de resposta (403, 404, etc.) podem ser divididos pelas mais diversas formas de acesso, como smartphone, desktop, ou qualquer dispositivo móvel.

### 12. Crawl Stats
Aqui são mostradas as páginas rastreadas nos últimos três meses, além dos tamanhos de download e dos tempos do download medidos em Kbs gastos.
Se apesar dos relatórios demonstrados e das suas ações estes números não baixarem, verifique se existem problemas de performance em seu site.

### 13. Security Issues
Imagine que você é o gestor de um site e se depara com uma mensagem dessas:
Este site pode prejudicar o seu computador.
Isso normalmente significa que seu site foi hackeado.
Para compreender melhor o que está ocorrendo, pelo Google Search Console, dê uma olhada na página “Security Issues”. Ali estarão informações sobre o problema, assim como as melhores formas para corrigí-lo.

### 14. Change of Address
Irá mover seu site principal para um domínio novo? Não esqueça de usar a função “Change of Adress”, que ajuda o Google a atualizar suas informações a respeito.

## Meta description
A descrição não tem impacto direto no posicionamento do seu site, mas o texto que estiver lá é o que convencerá ou não a pessoa a entrar na sua página.

## Título da página
O título precisa conter as palavras chaves para as quais você quer se posicionar. Tente usar essas palavras nele de forma natural. Além disso, tente não usar títulos muito longos, pois eles serão truncados. Lembre-se também de convencer o usuário a acessar seu site.

## Regra dos 3 cliques
A ideia é que para uma boa usabilidade e que o conteúdo do seu site seja facilmente encontrado, todos os conteúdos devem estar a no máximo 3 cliques de distância. Ou seja, navegando pelo site, você deve conseguir chegar sempre onde quer com no máximo 3 cliques.

## microformatos
Basicamente a grande vantagem é conseguir manipular de forma mais específica a visualização das minhas páginas nos resultados do Google. Dessa forma, posso incluir informações extras que consigam convencer mais ainda os potenciais clientes a acessarem minhas páginas.  

Para que o Google entenda a que se referem as informações da sua página, é preciso passar uma indicação a ele. Essa indicação não precisa, e nem deve, ficar visível para o usuário final, mas deve estar disponível para o spider que vai visitar sua página. Ou seja, precisamos passar um trecho de código que fique invisível para o usuário. É justamente esse o papel dos microformatos. São pequenas tags HTML que colocamos nas nossas páginas e que servem para definir as informações que estão no nosso site. Se você pensou em metadados, acertou. Os microformatos são metadados para sua página.
Existem microformatos para diferentes informações, como produtos, reviews, músicas, receitas e assim por diante. A lista é relativamente grande, mas não se preocupe. Assim que você pegar o funcionamento de 2 ou 3 metadados, o processo para usar os próximos no seu site é muito similar. Basta encontrar o metadado adequado para a informação que você quer descrever. Você consegue ver uma lista completa referente a isso no suporte do Webmaster Tools: https://developers.google.com/structured-data/.

## Breadcrumbs para organização
Para fazermos os breadcrumbs, o primeiro passo é que as partes do agrupamento estejam disponíveis na sua página. Ou seja, se quisermos indicar o agrupamento para Vídeo Games -> PS3 -> Jogos, faríamos algo como:
Você pode testar a visualização dos seus novos microformatos através da própria ferramenta do Google em <https://developers.google.com/structured-data/>. Basta ir em <http://bit.ly/richsnippet-test>.

Você pode descrever basicamente qualquer informação com os microformatos, mas algumas chamam a atenção, em especial as de produtos e avaliações.
A lista de microformatos suportados está em constante evolução e atualização. Recomendo fortemente que você acompanhe com frequência a lista com as opções suportadas, disponível em <https://developers.google.com/structured-data/> e siga a documentação para saber quais informações são passíveis de serem passadas.
Se você seguir uma estrutura completa de microformatos, adicionando endereços, informações sobre seus negócios, reviews e várias outras informações relevantes, será possível chegar a uma página com resultado similar à que fizemos na Caelum.


## Faça redirecionamentos e evite links quebrados
Possivelmente uma das coisas que mais influenciam negativamente os rankings (depois das técnicas maliciosas de ::black hat::) são os links quebrados. Muitas vezes acessamos um site e nos deparamos com desagradáveis telas de erro, escrito Error 404, ::page not found:: e algumas até contendo a descrição do erro. Imagina uma pessoa com nenhum conhecimento de informática vendo uma tela escrita 404. O que esse número significa para ela? É muito possível que nada!

## Lidando com conteúdo paginado
É comum vermos em sites onde as notícias são muito grandes, uma paginação, onde temos que clicar para ir para a continuação do conteúdo e assim sucessivamente até o final, ou caso queiramos, também é possível voltar atrás.
Mas também quando isso acontece, precisamos avisar o Google que se trata do mesmo conteúdo, apenas quebrado em N partes. Precisamos avisá-lo da paginação.
Podemos fazer isso através da adição da tag <link> no cabeçalho das suas páginas. Com ela, podemos dizer quais são as próximas páginas e anteriores. Por exemplo, na primeira página de um conteúdo paginado, temos que indicar qual é a próxima. Fazemos isso através do atributo rel com o valor next, além do href para indicar onde está o próximo conteúdo:

'<link rel="next" href="http://www.guste.com.br/cozinhando-2" />'
Já na segunda página, podemos indicar qual é a próxima, no caso a terceira página e qual é a anterior, a primeira, através do valor prev, no atributo rel:

'<link rel="next" href="http://www.guste.com.br/cozinhando-3" />'
'<link rel="prev" href="http://www.guste.com.br/cozinhando-1" />'
Adicionando esse código no head do HTML da sua página, os buscadores tratarão o conteúdo das diferentes páginas como sendo um único resultado.

## Configure seu robots.txt e o sitemaps.xml
O robots.txt irá instruir os robôs de busca sobre o que está acessível ou não em seu site, já o sitemaps.xml é uma dica para os robôs encontrarem todas as páginas possíveis do seu site. Vale lembrar que os robôs naturalmente irão navegar pelos links de suas páginas, mas caso haja alguma página que não esteja sendo linkada e ainda assim quer que seja indexada, o sitemaps.xml é o local ideal para fazer essa indicação.
Eventualmente queremos que algumas páginas do nosso site não sejam indexadas. Por exemplo, no site da Casa do Código, não queremos que os buscadores indexem a página do carrinho de compras, já que não há nada útil ali.
Para isso, podemos criar o arquivo robots.txt no nosso domínio, indicando que o carrinho de compras deve ser desabilitado da indexação:

'User-agent: *'
'Disallow: /cart'
Com isso, estamos falando que para qualquer User-agent (indicado pelo *), ou seja, qualquer buscador, o endereço /cart deve ser desabilitado da indexação e não deve jamais aparecer nos resultados da busca do usuário. Caso você queira bloquear apenas um buscador específico, basta especificá-lo no User-agent, como:

'User-agent: Googlebot'
'Disallow: /cart'

É possível também fazer o bloqueio de um grupo de páginas específicas, dado um trecho em comum da URL:

'User-agent: *'
'Disallow: /*.pdf$'
Nesse caso estamos falando que todos os arquivos (indicado pelo *) que contêm .pdfno seu final (indicado pelo $) não devem ser indexados.
Uma das linhas que você deve colocar no robots.txt é a indicação do mapa do seu site, dessa forma os buscadores têm uma dica de como eles poderão fazer o crawling do seu site e por quais páginas devem passar.

## Sitemap: http://www.site.com.br/sitemap.xml
Dentro desse arquivo XML, haverá, como o próprio nome do arquivo diz, um mapeamento com todas as páginas do seu site que você gostaria que fosse seguida pelos spiders.
Dentro do sitemap.xml você irá agrupar os diferentes mapeamentos por categorias que fizerem sentido para o seu site:
xml

          <?xml version="1.0" encoding="UTF-8"?>
          <urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"> 
            <url>
              <loc>http://www.site.com.br/produtos_map.xml</loc> 
            </url>
            <url>
              <loc>http://www.site.com.br/categorias_map.xml</loc> 
            </url>

          <!-- outras categorias que façam sentido para o seu negócio-->
        </urlset>
Em seguida, basta indicar dentro de cada sitemap quais são as suas páginas através da tag url. Dentro de cada URL você especifica também a frequência com que sua página é modificada, dando uma dica para que o buscar deve visitá-la dentro dessa frequência. Além disso, você também pode especificar detalhes da página, como imagens, vídeos, se é uma página mobile etc:

        <urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9" 
          xmlns:image="http://www.google.com/schemas/sitemap-image/1.1">

          <url>
            <loc>
            http://www.site.com.br/products/livro-startup-guia
            </loc>
            <lastmod>2014-11-18T11:22:28-02:00</lastmod>
            <changefreq>daily</changefreq>

            <image:image>
              <image:loc>
                  https://www.site.com.br/capaGuiaStartup.png
              </image:loc>
              <image:title>
                  Guia da Startup: Como startups e empresas 
                  estabelecidas podem criar produtos web 
                  rent&#xE1;veis
              </image:title>
            </image:image>
          </url>

          <!-- outras páginas -->
        </urlset>
Usando o robots.txt em conjunto com o sitemaps.xml, você pode controlar melhor como os indexadores passarão pelo seu site.

